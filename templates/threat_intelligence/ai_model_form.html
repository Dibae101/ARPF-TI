{% extends 'base.html' %}

{% block title %}{% if model %}Edit{% else %}Add{% endif %} AI Model - ARPF-TI{% endblock %}

{% block breadcrumbs %}
<nav class="flex mb-6" aria-label="Breadcrumb">
    <ol class="inline-flex items-center space-x-1 md:space-x-3">
        <li class="inline-flex items-center">
            <a href="{% url 'dashboard:index' %}" class="text-gray-500 hover:text-gray-700">Dashboard</a>
        </li>
        <li>
            <div class="flex items-center">
                <svg class="w-4 h-4 text-gray-400" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <path fill-rule="evenodd" d="M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z" clip-rule="evenodd"></path>
                </svg>
                <a href="{% url 'threat_intelligence:index' %}" class="ml-1 text-gray-500 hover:text-gray-700 md:ml-2">Threat Intelligence</a>
            </div>
        </li>
        <li>
            <div class="flex items-center">
                <svg class="w-4 h-4 text-gray-400" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <path fill-rule="evenodd" d="M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z" clip-rule="evenodd"></path>
                </svg>
                <a href="{% url 'threat_intelligence:ai_models_list' %}" class="ml-1 text-gray-500 hover:text-gray-700 md:ml-2">AI Models</a>
            </div>
        </li>
        <li aria-current="page">
            <div class="flex items-center">
                <svg class="w-4 h-4 text-gray-400" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <path fill-rule="evenodd" d="M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z" clip-rule="evenodd"></path>
                </svg>
                <span class="ml-1 font-medium text-gray-500 md:ml-2">{% if model %}Edit{% else %}Add{% endif %} Model</span>
            </div>
        </li>
    </ol>
</nav>
{% endblock %}

{% block content %}
<div class="mb-6 flex justify-between items-center">
    <div>
        <h1 class="text-2xl font-bold text-gray-900">{% if model %}Edit{% else %}Add{% endif %} AI Model</h1>
        <p class="mt-1 text-sm text-gray-600">Configure an AI model for threat intelligence analysis</p>
    </div>
    <a href="{% url 'threat_intelligence:ai_models_list' %}" class="btn-secondary">
        <i class="fas fa-arrow-left mr-2"></i> Back to Models
    </a>
</div>

<div class="bg-white rounded-lg shadow-md overflow-hidden">
    <div class="p-6">
        <form method="post" class="space-y-6" enctype="multipart/form-data">
            {% csrf_token %}
            
            <!-- Basic Info -->
            <div>
                <h2 class="text-lg font-semibold mb-4">Model Information</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-x-6 gap-y-4">
                    <div>
                        <label for="name" class="block text-sm font-medium text-gray-700">Model Name</label>
                        <input type="text" name="name" id="name" required 
                               value="{{ model.name|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm">
                    </div>
                    
                    <div>
                        <label for="model_type" class="block text-sm font-medium text-gray-700">Model Type</label>
                        <select name="model_type" id="model_type" required 
                                class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                onchange="toggleModelFields()">
                            <option value="">Select a type</option>
                            {% for value, label in model_types %}
                                <option value="{{ value }}" {% if model.model_type == value %}selected{% endif %}>{{ label }}</option>
                            {% endfor %}
                        </select>
                    </div>
                    
                    <div class="md:col-span-2">
                        <label for="description" class="block text-sm font-medium text-gray-700">Description</label>
                        <textarea name="description" id="description" rows="3"
                                  class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm">{{ model.description|default:'' }}</textarea>
                    </div>
                </div>
            </div>
            
            <!-- Model Settings -->
            <div class="pt-6 border-t border-gray-200">
                <h2 class="text-lg font-semibold mb-4">Model Settings</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-x-6 gap-y-4">
                    <div class="md:col-span-2">
                        <label for="file_path" class="block text-sm font-medium text-gray-700">File Path</label>
                        <input type="text" name="file_path" id="file_path" 
                               value="{{ model.file_path|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                               placeholder="/path/to/model.pkl">
                        <p class="mt-1 text-xs text-gray-500">Path to the model file (auto-generated if you upload a file below)</p>
                    </div>
                    
                    <div class="md:col-span-2">
                        <label for="model_file" class="block text-sm font-medium text-gray-700">Upload Model File</label>
                        <input type="file" name="model_file" id="model_file" 
                               class="mt-1 block w-full text-sm text-gray-500
                                      file:mr-4 file:py-2 file:px-4
                                      file:rounded-md file:border-0
                                      file:text-sm file:font-semibold
                                      file:bg-blue-50 file:text-blue-700
                                      hover:file:bg-blue-100">
                        <p class="mt-1 text-xs text-gray-500">Upload a .pkl or other model file (max size: 100MB)</p>
                    </div>
                    
                    <div id="sklearn-fields" class="model-specific-fields hidden md:col-span-2">
                        <label for="sklearn_module" class="block text-sm font-medium text-gray-700">Pickle Module/Class</label>
                        <input type="text" name="sklearn_module" id="sklearn_module" 
                               value="{{ model.sklearn_module|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                               placeholder="sklearn.ensemble.RandomForestClassifier">
                        <p class="mt-1 text-xs text-gray-500">Fully qualified class name (if needed)</p>
                    </div>
                    
                    <div id="tensorflow-fields" class="model-specific-fields hidden md:col-span-2">
                        <label for="tf_input_shape" class="block text-sm font-medium text-gray-700">Input Shape</label>
                        <input type="text" name="tf_input_shape" id="tf_input_shape" 
                               value="{{ model.tf_input_shape|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                               placeholder="(None, 100)">
                        <p class="mt-1 text-xs text-gray-500">Shape of the input tensor (comma-separated)</p>
                    </div>
                    
                    <div id="custom-fields" class="model-specific-fields hidden md:col-span-2">
                        <label for="custom_module" class="block text-sm font-medium text-gray-700">Python Module Path</label>
                        <input type="text" name="custom_module" id="custom_module" 
                               value="{{ model.custom_module|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                               placeholder="my_module.classifier">
                        <p class="mt-1 text-xs text-gray-500">Path to the Python module containing your model</p>
                        
                        <label for="custom_class" class="block text-sm font-medium text-gray-700 mt-4">Class Name</label>
                        <input type="text" name="custom_class" id="custom_class" 
                               value="{{ model.custom_class|default:'' }}"
                               class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                               placeholder="MyClassifier">
                        <p class="mt-1 text-xs text-gray-500">Name of the class to instantiate</p>
                    </div>
                    
                    <!-- New Llama Model Fields -->
                    <div id="llama-fields" class="model-specific-fields hidden md:col-span-2">
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-x-6 gap-y-4">
                            <div class="md:col-span-2">
                                <label for="llama_model_selection" class="block text-sm font-medium text-gray-700">Model Selection</label>
                                <select name="llama_model_selection" id="llama_model_selection" 
                                        class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                        onchange="toggleCustomModelPath()">
                                    <option value="">Select a pre-defined model</option>
                                    <option value="llama2-7b" {% if model.parameters.model_selection == 'llama2-7b' %}selected{% endif %}>Llama 2 (7B)</option>
                                    <option value="llama2-7b-chat" {% if model.parameters.model_selection == 'llama2-7b-chat' %}selected{% endif %}>Llama 2 Chat (7B)</option>
                                    <option value="llama3-8b" {% if model.parameters.model_selection == 'llama3-8b' %}selected{% endif %}>Llama 3 (8B)</option>
                                    <option value="custom" {% if model.parameters.model_selection == 'custom' %}selected{% endif %}>Custom HuggingFace Model</option>
                                </select>
                            </div>
                            
                            <div id="custom_model_path_container" class="md:col-span-2 {% if model.parameters.model_selection != 'custom' %}hidden{% endif %}">
                                <label for="llama_custom_model_path" class="block text-sm font-medium text-gray-700">Custom Model Path</label>
                                <input type="text" name="llama_custom_model_path" id="llama_custom_model_path" 
                                       value="{{ model.parameters.custom_model_path|default:'' }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="organization/model-name">
                                <p class="mt-1 text-xs text-gray-500">HuggingFace model identifier (e.g., mistralai/Mistral-7B-v0.1)</p>
                            </div>
                            
                            <div>
                                <label for="llama_quantization" class="block text-sm font-medium text-gray-700">Quantization</label>
                                <select name="llama_quantization" id="llama_quantization" 
                                        class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm">
                                    <option value="none" {% if model.parameters.quantization == 'none' %}selected{% endif %}>None (Full Precision)</option>
                                    <option value="4bit" {% if model.parameters.quantization == '4bit' %}selected{% endif %}>4-bit Quantization</option>
                                    <option value="8bit" {% if model.parameters.quantization == '8bit' %}selected{% endif %}>8-bit Quantization</option>
                                </select>
                                <p class="mt-1 text-xs text-gray-500">Lower precision uses less memory but may reduce quality</p>
                            </div>
                            
                            <div>
                                <label for="llama_max_seq_len" class="block text-sm font-medium text-gray-700">Max Sequence Length</label>
                                <input type="number" name="llama_max_seq_len" id="llama_max_seq_len" 
                                       value="{{ model.parameters.max_seq_len|default:2048 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="2048">
                                <p class="mt-1 text-xs text-gray-500">Maximum token length for model context</p>
                            </div>
                            
                            <div>
                                <label for="llama_temperature" class="block text-sm font-medium text-gray-700">Temperature</label>
                                <input type="number" name="llama_temperature" id="llama_temperature" step="0.1" min="0.1" max="2.0"
                                       value="{{ model.parameters.temperature|default:0.7 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="0.7">
                                <p class="mt-1 text-xs text-gray-500">Controls randomness (higher = more creative)</p>
                            </div>
                            
                            <div>
                                <label for="llama_top_p" class="block text-sm font-medium text-gray-700">Top-p Sampling</label>
                                <input type="number" name="llama_top_p" id="llama_top_p" step="0.05" min="0.05" max="1.0"
                                       value="{{ model.parameters.top_p|default:0.95 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="0.95">
                                <p class="mt-1 text-xs text-gray-500">Nucleus sampling parameter</p>
                            </div>
                            
                            <div>
                                <label for="llama_top_k" class="block text-sm font-medium text-gray-700">Top-k Sampling</label>
                                <input type="number" name="llama_top_k" id="llama_top_k" step="1" min="1" max="100"
                                       value="{{ model.parameters.top_k|default:50 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="50">
                                <p class="mt-1 text-xs text-gray-500">Limits vocabulary for next token selection</p>
                            </div>
                            
                            <div>
                                <label for="llama_repetition_penalty" class="block text-sm font-medium text-gray-700">Repetition Penalty</label>
                                <input type="number" name="llama_repetition_penalty" id="llama_repetition_penalty" step="0.1" min="1.0" max="2.0"
                                       value="{{ model.parameters.repetition_penalty|default:1.1 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="1.1">
                                <p class="mt-1 text-xs text-gray-500">Prevents repetitive text (higher = less repetition)</p>
                            </div>
                            
                            <div>
                                <label for="llama_max_new_tokens" class="block text-sm font-medium text-gray-700">Max New Tokens</label>
                                <input type="number" name="llama_max_new_tokens" id="llama_max_new_tokens" step="1" min="1" max="4096"
                                       value="{{ model.parameters.max_new_tokens|default:512 }}"
                                       class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm"
                                       placeholder="512">
                                <p class="mt-1 text-xs text-gray-500">Maximum number of tokens to generate in response</p>
                            </div>
                            
                            <div>
                                <label for="llama_device" class="block text-sm font-medium text-gray-700">Device</label>
                                <select name="llama_device" id="llama_device"
                                        class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm">
                                    <option value="cpu" {% if model.parameters.device == 'cpu' %}selected{% endif %}>CPU</option>
                                    <option value="cuda" {% if model.parameters.device == 'cuda' %}selected{% endif %}>CUDA (NVIDIA GPU)</option>
                                    <option value="mps" {% if model.parameters.device == 'mps' %}selected{% endif %}>MPS (Apple Silicon)</option>
                                </select>
                                <p class="mt-1 text-xs text-gray-500">Hardware device to run the model on</p>
                            </div>
                        </div>
                        
                        <div class="mt-4">
                            <label for="llama_default_system_prompt" class="block text-sm font-medium text-gray-700">Default System Prompt</label>
                            <textarea name="llama_default_system_prompt" id="llama_default_system_prompt" rows="3"
                                      class="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500 sm:text-sm">{{ model.parameters.default_system_prompt|default:'You are an AI security analyst. Analyze the following data and determine if it represents a security threat.' }}</textarea>
                            <p class="mt-1 text-xs text-gray-500">System prompt that guides the model's behavior</p>
                        </div>
                    </div>
                    
                    {% if model %}
                    <div>
                        <div class="flex items-center h-5 mt-6">
                            <input type="checkbox" name="is_active" id="is_active" 
                                   {% if model.is_active %}checked{% endif %}
                                   class="h-4 w-4 rounded border-gray-300 text-blue-600 focus:ring-blue-500">
                            <label for="is_active" class="ml-2 block text-sm text-gray-700">
                                Active
                            </label>
                        </div>
                        <p class="mt-1 text-xs text-gray-500">Only active models will be used for classification</p>
                    </div>
                    {% endif %}
                    {% if model %}
                    <input type="hidden" name="model_id" value="{{ model.id }}">
                    {% endif %}
                </div>
            </div>
            
            <div class="mt-6 flex justify-end">
                <a href="{% url 'threat_intelligence:ai_models_list' %}" class="btn-secondary mr-3">Cancel</a>
                <button type="submit" class="btn-primary">Save Model</button>
            </div>
        </form>
    </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const modelTypeSelect = document.getElementById('model_type');
    const modelSpecificFields = document.querySelectorAll('.model-specific-fields');
    
    function showModelFields() {
        // Hide all model-specific fields first
        modelSpecificFields.forEach(field => {
            field.classList.add('hidden');
        });
        
        // Show fields based on selected model type
        const selectedType = modelTypeSelect.value;
        if (selectedType === 'sklearn') {
            document.getElementById('sklearn-fields').classList.remove('hidden');
        } else if (selectedType === 'tensorflow') {
            document.getElementById('tensorflow-fields').classList.remove('hidden');
        } else if (selectedType === 'custom') {
            document.getElementById('custom-fields').classList.remove('hidden');
        } else if (selectedType === 'llama') {
            document.getElementById('llama-fields').classList.remove('hidden');
        }
    }
    
    // Show fields on page load
    showModelFields();
    
    // Show fields when model type changes
    modelTypeSelect.addEventListener('change', showModelFields);
});
</script>
{% endblock %}

{% block extra_scripts %}
<script>
    document.addEventListener('DOMContentLoaded', function() {
        const modelTypeSelect = document.getElementById('model_type');
        const llamaFields = document.getElementById('llama-fields');
        const openaiFields = document.getElementById('openai-fields');
        const huggingfaceFields = document.getElementById('huggingface-fields');
        
        // Handle model type change
        modelTypeSelect.addEventListener('change', function() {
            // Hide all model-specific fields first
            llamaFields.classList.add('hidden');
            openaiFields.classList.add('hidden');
            if (huggingfaceFields) huggingfaceFields.classList.add('hidden');
            
            // Show the selected model's fields
            if (this.value === 'llama') {
                llamaFields.classList.remove('hidden');
            } else if (this.value === 'openai') {
                openaiFields.classList.remove('hidden');
            } else if (this.value === 'huggingface' && huggingfaceFields) {
                huggingfaceFields.classList.remove('hidden');
            }
        });
        
        // Trigger change event to set initial state
        const changeEvent = new Event('change');
        modelTypeSelect.dispatchEvent(changeEvent);
    });
    
    // Function to toggle custom model path visibility
    function toggleCustomModelPath() {
        const modelSelection = document.getElementById('llama_model_selection');
        const customPathContainer = document.getElementById('custom_model_path_container');
        
        if (modelSelection.value === 'custom') {
            customPathContainer.classList.remove('hidden');
        } else {
            customPathContainer.classList.add('hidden');
        }
    }
</script>
{% endblock %}